{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7Ccpy4OkFMEM"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pickle import load, dump\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import datetime\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mish(nn.Module):\n",
    "    @staticmethod\n",
    "    def mish(x):\n",
    "        return x * torch.tanh(F.softplus(x))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return Mish.mish(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GLU(nn.Module):\n",
    "    def forward(self, x):\n",
    "        channel = x.size(1)\n",
    "        assert channel % 2 == 0, 'must divide by 2.'\n",
    "        return x[:, :channel//2] * torch.sigmoid(x[:, channel//2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PixelwiseNormalization(nn.Module):\n",
    "    def pixel_norm(self, x):\n",
    "        eps = 1e-8\n",
    "        return x * torch.rsqrt(torch.mean(x * x, 1, keepdim=True) + eps)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.pixel_norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorBlock(nn.Module):\n",
    "    def __init__(self, input_nc, output_nc, n_channel):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.upsample = nn.Upsample(scale_factor=2)\n",
    "        self.conv = nn.Conv2d(input_nc, output_nc * 2, kernel_size=3, stride=1, padding=1)\n",
    "        self.normalize = PixelwiseNormalization()\n",
    "        self.activate = GLU()\n",
    "        \n",
    "    def forward(self, image):\n",
    "        image = self.upsample(image)\n",
    "        image = self.conv(image)\n",
    "        image = self.normalize(image)\n",
    "        image = self.activate(image)\n",
    "        \n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscriminatorBlock(nn.Module):\n",
    "    def __init__(self, input_nc, output_nc):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(input_nc, output_nc, kernel_size=4, stride=2, padding=1),  # downsample\n",
    "            PixelwiseNormalization(),\n",
    "            Mish(),\n",
    "            nn.Conv2d(output_nc, output_nc, kernel_size=3, stride=1, padding=1)\n",
    "        )\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.AvgPool2d(2),\n",
    "            nn.Conv2d(input_nc, output_nc, kernel_size=3, stride=1, padding=1)\n",
    "        )\n",
    "           \n",
    "        self.activation = nn.Sequential(\n",
    "            PixelwiseNormalization(),\n",
    "            Mish()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.model(x)\n",
    "        skip = self.conv(x)\n",
    "        out = out + skip\n",
    "        out = self.activation(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d53nPWZFheB4"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, num_depth, num_fmap, n_channel=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_depth = num_depth\n",
    "        self.blocks = nn.ModuleList([GeneratorBlock(num_fmap(i), num_fmap(i + 1), n_channel) for i in range(num_depth)])\n",
    "        self.toRGB = nn.Sequential(\n",
    "            nn.Conv2d(num_fmap(num_depth), n_channel, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        \n",
    "        x = self.toRGB(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c0TccaIsSJxd"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, num_depth, num_fmap, n_channel=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fromRGB = nn.Conv2d(n_channel, num_fmap(num_depth), kernel_size=3, stride=1, padding=1)\n",
    "        self.blocks = nn.ModuleList([DiscriminatorBlock(num_fmap(i+1), num_fmap(i)) for i in range(num_depth)][::-1])\n",
    "        \n",
    "        self.z_decoder = nn.Conv2d(num_fmap(0), num_fmap(0), kernel_size=4, stride=2, padding=1)\n",
    "        \n",
    "        self.conv_feature = nn.Conv2d(num_fmap(0) + num_fmap(0), num_fmap(0), kernel_size=3, stride=1, padding=1)\n",
    "        self.conv_patch = nn.Conv2d(num_fmap(0), 1, kernel_size=3, stride=1, padding=1)\n",
    "    \n",
    "    def forward(self, x, z):\n",
    "        x = self.fromRGB(x)\n",
    "            \n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        \n",
    "        z = self.z_decoder(z).expand(x.shape)\n",
    "        feature = self.conv_feature(torch.cat([x, z], dim=1))\n",
    "        out = self.conv_patch(feature)\n",
    "        \n",
    "        return out, feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    class BasicBlock(nn.Module):\n",
    "        def __init__(self, dim_in, dim_out):\n",
    "            super().__init__()\n",
    "            self.block = nn.Sequential(\n",
    "                nn.Upsample(scale_factor=2),\n",
    "                nn.Conv2d(dim_in, dim_out * 2, kernel_size=3, stride=1, padding=1),\n",
    "                PixelwiseNormalization(),\n",
    "                GLU()\n",
    "            )\n",
    "        def forward(self, x):\n",
    "            return self.block(x)\n",
    "    \n",
    "    def __init__(self, num_depth, num_fmap, n_channel=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fromRGB = nn.Conv2d(n_channel, num_fmap(num_depth), kernel_size=3, stride=1, padding=1)\n",
    "        self.blocks = nn.ModuleList([DiscriminatorBlock(num_fmap(i+1), num_fmap(i)) for i in range(num_depth)][::-1])\n",
    "        self.to_z = Encoder.BasicBlock(num_fmap(0), num_fmap(0))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fromRGB(x)\n",
    "        \n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        \n",
    "        z = F.adaptive_avg_pool2d(x, (1, 1))\n",
    "        z = self.to_z(z)\n",
    "        \n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Solver:\n",
    "    def __init__(self, args):\n",
    "        use_cuda = torch.cuda.is_available() if not args.cpu else False\n",
    "        self.device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        print(f'Use Device: {self.device}')\n",
    "        \n",
    "        def num_fmap(stage):\n",
    "            base_size = self.args.image_size\n",
    "            fmap_base = base_size * 4\n",
    "            fmap_max = base_size // 2\n",
    "            fmap_decay = 1.0\n",
    "            return min(int(fmap_base / (2.0 ** (stage * fmap_decay))), fmap_max)\n",
    "        \n",
    "        self.args = args\n",
    "        self.feed_dim = num_fmap(0)\n",
    "        self.max_depth = int(np.log2(self.args.image_size)) - 1\n",
    "        self.pseudo_aug = 0.0\n",
    "        self.epoch = 0\n",
    "        self.scorelist = []\n",
    "        \n",
    "        self.netG = Generator(self.max_depth, num_fmap).to(self.device)\n",
    "        self.netD = Discriminator(self.max_depth, num_fmap).to(self.device)\n",
    "        self.netE = Encoder(self.max_depth, num_fmap).to(self.device)\n",
    "        \n",
    "        self.netG.apply(self.weights_init)\n",
    "        self.netD.apply(self.weights_init)\n",
    "        self.netE.apply(self.weights_init)\n",
    "        \n",
    "        self.optimizer_G = optim.Adam(self.netG.parameters(), lr=self.args.lr, betas=(0, 0.9))\n",
    "        self.optimizer_D = optim.Adam(self.netD.parameters(), lr=self.args.lr * self.args.mul_lr_dis, betas=(0, 0.9))\n",
    "        self.optimizer_E = optim.Adam(self.netE.parameters(), lr=self.args.lr * self.args.mul_lr_dis, betas=(0, 0.9))\n",
    "    \n",
    "    def weights_init(self, module):\n",
    "        if type(module) == nn.Linear or type(module) == nn.Conv2d or type(module) == nn.ConvTranspose2d:\n",
    "            nn.init.kaiming_normal_(module.weight)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.fill_(0)\n",
    "            \n",
    "    def save_state(self):\n",
    "        self.netG.cpu(), self.netD.cpu()\n",
    "        torch.save(self.netG.state_dict(), os.path.join(self.args.weight_dir, f'weight_G.pth'))\n",
    "        torch.save(self.netD.state_dict(), os.path.join(self.args.weight_dir, f'weight_D.pth'))\n",
    "        self.netG.to(self.device), self.netD.to(self.device)\n",
    "        \n",
    "    def load_state(self):\n",
    "        if (os.path.exists('weight_G.pth') and os.path.exists('weight_D.pth')):\n",
    "            self.netG.load_state_dict(torch.load('weight_G.pth', map_location=self.device))\n",
    "            self.netD.load_state_dict(torch.load('weight_D.pth', map_location=self.device))\n",
    "            self.state_loaded = True\n",
    "            print('Loaded network state.')\n",
    "    \n",
    "    def save_resume(self):\n",
    "        with open(os.path.join('.', f'resume.pkl'), 'wb') as f:\n",
    "            dump(self, f)\n",
    "    \n",
    "    def load_resume(self):\n",
    "        if os.path.exists('resume.pkl'):\n",
    "            with open(os.path.join('.', 'resume.pkl'), 'rb') as f:\n",
    "                print('Load resume.')\n",
    "                return load(f)\n",
    "        else:\n",
    "            return self\n",
    "        \n",
    "    def trainGAN(self, epoch, real_img, a=0, b=1, c=1):\n",
    "        ### Train with LSGAN.\n",
    "        ### for example, (a, b, c) = 0, 1, 1 or (a, b, c) = -1, 1, 0\n",
    "        \n",
    "        # ================================================================================ #\n",
    "        #                             Train the discriminator                              #\n",
    "        # ================================================================================ #\n",
    "        \n",
    "        random_data = torch.randn(real_img.size(0), self.feed_dim, 2, 2).to(self.device)\n",
    "        \n",
    "        # Compute loss with real images.\n",
    "        real_z_score = self.netE(real_img)\n",
    "        real_src_score, _ = self.netD(real_img, real_z_score)\n",
    "        real_src_loss = torch.sum((real_src_score - b) ** 2)\n",
    "        \n",
    "        # Compute loss with fake images.\n",
    "        fake_img = self.netG(random_data)\n",
    "        fake_src_score, _ = self.netD(fake_img, random_data)\n",
    "        \n",
    "        p = random.uniform(0, 1)\n",
    "        if 1 - self.pseudo_aug < p:\n",
    "            fake_src_loss = torch.sum((fake_src_score - b) ** 2) # Pseudo: fake is real.\n",
    "        else:\n",
    "            fake_src_loss = torch.sum((fake_src_score - a) ** 2)\n",
    "        \n",
    "        # Update Probability Augmentation.\n",
    "        lz = (torch.sign(torch.logit(real_src_score)).mean()\n",
    "              - torch.sign(torch.logit(fake_src_score)).mean()) / 2\n",
    "        if lz > self.args.aug_threshold:\n",
    "            self.pseudo_aug += 0.01\n",
    "        else:\n",
    "            self.pseudo_aug -= 0.01\n",
    "        self.pseudo_aug = min(1, max(0, self.pseudo_aug))\n",
    "        \n",
    "        # Backward and optimize.\n",
    "        d_loss = 0.5 * (real_src_loss + fake_src_loss) / self.batch_size\n",
    "        self.optimizer_D.zero_grad()\n",
    "        d_loss.backward()\n",
    "        self.optimizer_D.step()\n",
    "        \n",
    "        # Logging.\n",
    "        loss = {}\n",
    "        loss['D/loss'] = d_loss.item()\n",
    "        loss['Augment/prob'] = self.pseudo_aug\n",
    "        \n",
    "        # ================================================================================ #\n",
    "        #                               Train the generator                                #\n",
    "        # ================================================================================ #\n",
    "        \n",
    "        random_data = torch.randn(real_img.size(0), self.feed_dim, 2, 2).to(self.device)\n",
    "        \n",
    "        # Compute loss with fake images.\n",
    "        fake_img = self.netG(random_data)\n",
    "        fake_src_score, _ = self.netD(fake_img, random_data)\n",
    "        fake_src_loss = torch.sum((fake_src_score - c) ** 2)\n",
    "        \n",
    "        # Backward and optimize.\n",
    "        g_loss = 0.5 * fake_src_loss / self.batch_size\n",
    "        self.optimizer_G.zero_grad()\n",
    "        g_loss.backward()\n",
    "        self.optimizer_G.step()\n",
    "        \n",
    "        # Logging.\n",
    "        loss['G/loss'] = g_loss.item()\n",
    "        \n",
    "        # ================================================================================ #\n",
    "        #                               Train the encoder                                  #\n",
    "        # ================================================================================ #\n",
    "        \n",
    "        real_z_score = self.netE(real_img)\n",
    "        real_src_score, _ = self.netD(real_img, real_z_score)\n",
    "        real_src_loss = torch.sum((real_src_score - c) ** 2)\n",
    "        \n",
    "        # Backward and optimize.\n",
    "        e_loss = 0.5 * real_src_loss / self.batch_size\n",
    "        self.optimizer_E.zero_grad()\n",
    "        e_loss.backward()\n",
    "        self.optimizer_E.step()\n",
    "        \n",
    "        # Logging.\n",
    "        loss['E/loss'] = e_loss.item()\n",
    "        \n",
    "        # Save\n",
    "        self.save_state()\n",
    "        img_name = 'generator_last.png'\n",
    "        img_path = os.path.join(self.args.result_dir, img_name)\n",
    "        save_image(fake_img, img_path)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def score(self, image, lambda_anomaly=0.1):\n",
    "        self.netG.eval()\n",
    "        self.netD.eval()\n",
    "        self.netE.eval()\n",
    "        \n",
    "        z = self.netE(image)\n",
    "        fake = self.netG(z)\n",
    "        fake_score, fake_feature = self.netD(fake, z)\n",
    "        real_score, real_feature = self.netD(image, z)\n",
    "        \n",
    "        residual_loss = torch.abs(image - fake)\n",
    "        residual_loss = residual_loss.view(residual_loss.shape[0], -1)\n",
    "        residual_loss = residual_loss.sum(dim=1)\n",
    "        \n",
    "        discrimination_loss = torch.abs(real_feature - fake_feature)\n",
    "        discrimination_loss = discrimination_loss.view(discrimination_loss.shape[0], -1)\n",
    "        discrimination_loss = discrimination_loss.sum(dim=1)\n",
    "        \n",
    "        score = (1 - lambda_anomaly) * residual_loss + lambda_anomaly * discrimination_loss\n",
    "        return score.item()\n",
    "    \n",
    "    def capture(self):\n",
    "        hyper_params = {}\n",
    "        hyper_params['Device ID'] = self.args.device_id\n",
    "        hyper_params['Result Dir'] = self.args.result_dir\n",
    "        hyper_params['Weight Dir'] = self.args.weight_dir\n",
    "        hyper_params['Image Size'] = self.args.image_size\n",
    "        hyper_params['Learning Rate'] = self.args.lr\n",
    "        hyper_params[\"Mul Discriminator's LR\"] = self.args.mul_lr_dis\n",
    "        hyper_params['Num ScoreList'] = self.args.num_scorelist\n",
    "        hyper_params['Probability Aug-Threshold'] = self.args.aug_threshold\n",
    "        \n",
    "        self.batch_size = 1\n",
    "        grayscale = transforms.Grayscale(num_output_channels=1)\n",
    "        resize = transforms.Resize((self.args.image_size, self.args.image_size))\n",
    "        \n",
    "        now = datetime.datetime.now()\n",
    "        log_lotate = datetime.datetime(now.year, now.month, now.day + 1)\n",
    "        \n",
    "        while True:\n",
    "            self.netG.train()\n",
    "            self.netD.train()\n",
    "            self.netE.train()\n",
    "            \n",
    "            capture = cv2.VideoCapture(self.args.device_id)\n",
    "            try:\n",
    "                _, frame = capture.read()\n",
    "            finally:\n",
    "                capture.release()\n",
    "            timestamp = datetime.datetime.now()\n",
    "            \n",
    "            if timestamp >= log_lotate:\n",
    "                if not os.path.exists(f'log_{log_lotate.year}-{log_lotate.month}-{log_lotate.day}'):\n",
    "                    os.rename(self.args.result_dir, f'log_{log_lotate.year}-{log_lotate.month}-{log_lotate.day}')\n",
    "                    os.mkdir(self.args.result_dir)\n",
    "                log_lotate = datetime.datetime(now.year, now.month, now.day + 1)\n",
    "            \n",
    "            self.epoch += 1\n",
    "            epoch_loss_G = 0.0\n",
    "            epoch_loss_D = 0.0\n",
    "            epoch_loss_E = 0.0\n",
    "\n",
    "            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image = torch.Tensor(rgb).permute(2, 0, 1) / 255\n",
    "            image = image.unsqueeze(0).to(self.device)\n",
    "            image = grayscale(image)\n",
    "            image = resize(image)\n",
    "\n",
    "            loss = self.trainGAN(self.epoch, image)\n",
    "\n",
    "            epoch_loss_D += loss['D/loss']\n",
    "            epoch_loss_G += loss['G/loss']\n",
    "            epoch_loss_E += loss['E/loss']\n",
    "\n",
    "            epoch_loss = epoch_loss_G + epoch_loss_D + epoch_loss_E\n",
    "                \n",
    "            score = self.score(image)\n",
    "            self.scorelist += [score]\n",
    "            self.scorelist = self.scorelist[-self.args.num_scorelist:]\n",
    "            \n",
    "            print(f'{timestamp}: AnomalyScore {score} (TotalLoss {epoch_loss})')\n",
    "            \n",
    "            if score >= max(self.scorelist) and len(self.scorelist) >= self.args.num_scorelist:\n",
    "                img_name = f'{timestamp}_{score}.jpg'\n",
    "                img_path = os.path.join(self.args.result_dir, img_name)\n",
    "                cv2.imwrite(img_path, frame)\n",
    "            \n",
    "            if not self.args.noresume:\n",
    "                self.save_resume()\n",
    "    \n",
    "    def generate(self, num=100):\n",
    "        self.netG.eval()\n",
    "        \n",
    "        for _ in range(num):\n",
    "            random_data = torch.randn(1, self.feed_dim, 2, 2).to(self.device)\n",
    "            fake_img = self.netG(random_data)[0][0,:]\n",
    "            save_image(fake_img, os.path.join(self.args.result_dir, f'generated_{time.time()}.png'))\n",
    "        print('New picture was generated.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    solver = Solver(args)\n",
    "    solver.load_state()\n",
    "    \n",
    "    if not args.noresume:\n",
    "        solver = solver.load_resume()\n",
    "        solver.args = args\n",
    "    \n",
    "    if args.generate > 0:\n",
    "        solver.generate(args.generate)\n",
    "        return\n",
    "    \n",
    "    solver.capture()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--device_id', type=int, default=0)\n",
    "    parser.add_argument('--result_dir', type=str, default='log')\n",
    "    parser.add_argument('--weight_dir', type=str, default='log')\n",
    "    parser.add_argument('--image_size', type=int, default=16)\n",
    "    parser.add_argument('--lr', type=float, default=0.0001)\n",
    "    parser.add_argument('--mul_lr_dis', type=float, default=4)\n",
    "    parser.add_argument('--num_scorelist', type=int, default=1000)\n",
    "    parser.add_argument('--aug_threshold', type=float, default=0.6)\n",
    "    parser.add_argument('--cpu', action='store_true')\n",
    "    parser.add_argument('--generate', type=int, default=0)\n",
    "    parser.add_argument('--noresume', action='store_true')\n",
    "    \n",
    "    args, unknown = parser.parse_known_args()\n",
    "    \n",
    "    if not os.path.exists(args.result_dir):\n",
    "        os.mkdir(args.result_dir)\n",
    "    if not os.path.exists(args.weight_dir):\n",
    "        os.mkdir(args.weight_dir)\n",
    "    \n",
    "    main(args)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CycleGAN.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
